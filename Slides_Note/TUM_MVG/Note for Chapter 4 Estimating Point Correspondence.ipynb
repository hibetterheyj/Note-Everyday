{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Note-for-Chapter-4-Estimating-Point-Correspondence\" data-toc-modified-id=\"Note-for-Chapter-4-Estimating-Point-Correspondence-1\">Note for Chapter 4 Estimating Point Correspondence</a></span><ul class=\"toc-item\"><li><span><a href=\"#From-Photometry-to-Geometry\" data-toc-modified-id=\"From-Photometry-to-Geometry-1.1\">From Photometry to Geometry</a></span><ul class=\"toc-item\"><li><span><a href=\"#Non-rigid-Deformation\" data-toc-modified-id=\"Non-rigid-Deformation-1.1.1\">Non-rigid Deformation</a></span></li><li><span><a href=\"#Small-Deformation-versus-Wide-Baseline\" data-toc-modified-id=\"Small-Deformation-versus-Wide-Baseline-1.1.2\">Small Deformation versus Wide Baseline</a></span></li></ul></li><li><span><a href=\"#Small-Deformation-&amp;-Optical-Flow\" data-toc-modified-id=\"Small-Deformation-&amp;-Optical-Flow-1.2\">Small Deformation &amp; Optical Flow</a></span><ul class=\"toc-item\"><li><span><a href=\"#Small-Deformation\" data-toc-modified-id=\"Small-Deformation-1.2.1\">Small Deformation</a></span></li><li><span><a href=\"#Optic-Flow-Estimation\" data-toc-modified-id=\"Optic-Flow-Estimation-1.2.2\">Optic Flow Estimation</a></span></li></ul></li><li><span><a href=\"#The-Lucas-Kanade-Method\" data-toc-modified-id=\"The-Lucas-Kanade-Method-1.3\">The Lucas-Kanade Method</a></span><ul class=\"toc-item\"><li><span><a href=\"#Estimating-Local-Displacements\" data-toc-modified-id=\"Estimating-Local-Displacements-1.3.1\">Estimating Local Displacements</a></span></li><li><span><a href=\"#When-can-Small-Motion-be-Estimated?\" data-toc-modified-id=\"When-can-Small-Motion-be-Estimated?-1.3.2\">When can Small Motion be Estimated?</a></span></li><li><span><a href=\"#A-Simple-Feature-Tracking-Algorithm\" data-toc-modified-id=\"A-Simple-Feature-Tracking-Algorithm-1.3.3\">A Simple Feature Tracking Algorithm</a></span></li></ul></li><li><span><a href=\"#Feature-Point-Extraction\" data-toc-modified-id=\"Feature-Point-Extraction-1.4\">Feature Point Extraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Robust-Feature-Point-Extraction\" data-toc-modified-id=\"Robust-Feature-Point-Extraction-1.4.1\">Robust Feature Point Extraction</a></span></li></ul></li><li><span><a href=\"#Wide-Baseline-Matching\" data-toc-modified-id=\"Wide-Baseline-Matching-1.5\">Wide Baseline Matching</a></span><ul class=\"toc-item\"><li><span><a href=\"#Extensions-to-Larger-Baseline\" data-toc-modified-id=\"Extensions-to-Larger-Baseline-1.5.1\">Extensions to Larger Baseline</a></span></li><li><span><a href=\"#Normalized-Cross-Correlation\" data-toc-modified-id=\"Normalized-Cross-Correlation-1.5.2\">Normalized Cross Correlation</a></span></li><li><span><a href=\"#Special-Case:-Optimal-Affine-Transformation\" data-toc-modified-id=\"Special-Case:-Optimal-Affine-Transformation-1.5.3\">Special Case: Optimal Affine Transformation</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note for Chapter 4 Estimating Point Correspondence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bilibili视频[lecture6](https://www.bilibili.com/video/av24149942?p=6), [lecture7](https://www.bilibili.com/video/av24149942?p=7)\n",
    "\n",
    "- 参考书目\n",
    "\n",
    "```\n",
    "Ma, Yi, et al. An invitation to 3-d vision: from images to geometric models. Vol. 26. Springer Science & Business Media, 2012.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Photometry to Geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we do not actually observe points or lines, but rather **brightness or color values** at the individual pixels\n",
    "\n",
    "主要关注光照和颜色的变化而非直接关注点与线的变化\n",
    "\n",
    "- photometric representation ==> geometric epresentation\n",
    "    - 使用特征表达点identify points with characteristic image features\n",
    "    - 寻找关联性：associate these points with corresponding points\n",
    "\n",
    "通过关键点的匹配可以帮助探知3D结构，但是，本方法是次优的：选出少量关键点，然后会丢失掉大量可能存在有用信息的特征点（this\n",
    "approach is suboptimal: By **selecting a small number of feature points** from each image, we **throw away a large amount of potentially useful information** contained in each image）\n",
    "\n",
    "- Limitations：\n",
    "    - retaining all image information is computationally challenging\n",
    "    - tracking of 3D objects from a moving camera in real time - even with limited processing power\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-rigid Deformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在一般算法中，假设物体进行刚体运动：但是现实世界中有可能发生变形（deformation）与遮挡（occlusion）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Deformation versus Wide Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在点的匹配主要看两种情况——小形变（Small deformation）与（Wide baseline stereo）：\n",
    "\n",
    "- Small deformation：one frame to the other is assumed to be (infinitesimally) small，使用光流方法解决\n",
    "    - Lucas/Kanade (sparse)\n",
    "    - Horn/Schunck (dense)\n",
    "    one can also track the displacement of a few feature points which is typically faster （跟踪一系列点还可以较快的速度）\n",
    "\n",
    "- Wide baseline stereo：the displacement is assumed to be large.\n",
    "    - one typically selects a small number of feature points in each\n",
    "of the images and develops efficient methods to find an appropriate pairing of points.（需要开发出更为高效的方法去实现实时少数点的匹配）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Deformation & Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Deformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 参考书目第70页\n",
    "\n",
    "one can envision two opposite strategies: \n",
    "- **one is to choose a complex transformation that captures the changes undergone by the entire image**, or \n",
    "- **one can pick a simple transformation, and then restrict the attention to only those regions in the image whose motion can be captured, within reasonable bounds, by the chosen transformation.**\n",
    "\n",
    "本部分主要主要关注后面的情况，假设对一静止物体的不同角度进行建模，现有图上对应点$ \\mathbf{x_1}, \\mathbf{x_2} $；假设两相机间的位移为刚体运动$ (R, T) $（displacement between the two camera viewpoints is a rigid-body motion.），如下所示：\n",
    "$$\n",
    "\\mathbf{x_2} = h(\\mathbf{x_1}) = \\frac{1}{\\lambda_2(\\mathbf{X})}\n",
    "(R \\lambda_1(\\mathbf{X}) + T)\n",
    "$$\n",
    "\n",
    "在局部则可以对于运动函数$ h $进行建模（The function h describes the transformation of the domain, or \"image motion,\"）：\n",
    "\n",
    "- 平移模型Translational model：\n",
    "\n",
    "$$ h(x) = x + b $$\n",
    "其中，$ b $为偏移offset\n",
    "\n",
    "- 仿射模型Affine model：\n",
    "$$ h(x) = Ax + b $$\n",
    "\n",
    "![Two basic types of local domain W (x) deformation. Left: translational; right:\n",
    "affine](./Image/Chap4_affine.jpg)\n",
    "\n",
    "This model is a good approximation for small\n",
    "planar patches parallel to the image plane undergoing an arbitrary translation and\n",
    "rotation about the optical axis, and modest rotation about an axis orthogonal to it.\n",
    "\n",
    "特别地，2D放射模型可以如下所示：\n",
    "$$ h(x) = x + u(x)\\ , $$\n",
    "其中\n",
    "$$ u(x) = S(x)p\n",
    "= \\left( \\begin{array}{cccccc}\n",
    "x & y & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & x & y & 1\n",
    "\\end{array} \\right)\n",
    "\\left( \\begin{array}{cccccc}\n",
    "p_1 & p_2 & p_3 & p_4 & p_5 & p_6\n",
    "\\end{array} \\right)^{\\mathsf{T}}\n",
    "=\n",
    "\\left( \\begin{array}{c}\n",
    "xp_1 + yp_2 + p_3 \\\\ xp_4 + yp_5 + p_6\n",
    "\\end{array} \\right)\n",
    "\\ . $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optic Flow Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Lucas-Kanade method generates sparse flow vectors under the assumption of constant motion in a local neighborhood**, whereas \n",
    "- **the Horn-Schunck method generates a dense flow field under the assumption of spatially smooth motion.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Lucas-Kanade Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设：\n",
    "- Brightness Constancy Assumption\n",
    "\n",
    "$x(t)$ 表示随时间 $t$ 变化的点，因此视频序列$ l(x,t) $，因此：\n",
    "$$\n",
    "l(x(t), t) = \\mathrm{const}. \\forall t\n",
    "$$\n",
    "\n",
    "因而推导出导数应该为0的光流约束方程【(differential) optical flow\n",
    "constraint】：\n",
    "$$\n",
    "\\frac{d}{dt}l(x(t), t) = \\Delta I^{\\mathsf{T}}\\left(\\frac{dx}{dt} \\right) + \\frac{\\partial I}{\\partial t} =0,\n",
    "\\quad\n",
    "\\Delta I^{\\mathsf{T}} = \\left(\\begin{array}{c}\n",
    "\\frac{\\partial I}{\\partial x} \\\\\n",
    "\\frac{\\partial I}{\\partial y}\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$\n",
    "其中，$\\Delta I^{\\mathsf{T}} $为对于图片本身在空间各个位置的导数，$V = \\frac{dx}{dt} $可以理解为光流速度速度，此外$ \\frac{\\partial I}{\\partial t} $图片对于时间的限制！**但是公式难以直接解出**\n",
    "\n",
    "apecture probelm：只能光测出垂直于图片中点位置的运动\n",
    "\n",
    "- 邻域$ W(x) $内的常速运动Constant motion in a neighborhood\n",
    "    - 邻域$ W(x) $选择十个难题，一般要出现相关的角度corner\n",
    "    - 现实中并不适用，传感器的噪音可能有微笑的变化，难以完美实现\n",
    "    公式如下所示：\n",
    "    $$\n",
    "    \\Delta I(x',t)^{\\mathsf{T}} + \\frac{\\partial I}{\\partial t}(x', t) = 0 \\quad \\forall x'\\in W(x)\n",
    "    $$\n",
    "\n",
    "Lucas and Kanade (1981) therefore compute the best velocity vector v for the point x by minimizing the least squares error（最小化二范数），cost (energy) function如下所示：\n",
    "$$\n",
    "E(v) = \\int_{W(x)} \\left| \\Delta I(x',t)^{\\mathsf{T}} + I_t(x', t) \\right|^2 dx'\n",
    "$$\n",
    "\n",
    "同样的方法，导数为0：\n",
    "$$\n",
    "\\frac{dE}{dc} = 2Mv + 2q =0,\n",
    "$$\n",
    "其中，\n",
    "$$\n",
    "M = \\int_{W(x)} \\Delta I \\Delta I^{\\mathsf{T}} dx', \n",
    "\\quad and \\quad \n",
    "q = \\int_{W(x)} I_t \\Delta I dx'.\n",
    "$$\n",
    "\n",
    "若$ \\mathrm{det}(M) \\not= 0 $，那么问题的解可以得出：$ v = -M^{-1} q $。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating Local Displacements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样分为两种模型：\n",
    "\n",
    "- Translational motion: Lucas & Kanade ’81:\n",
    "\n",
    "最小化平方和，如下所示：\n",
    "$$\n",
    "E(b) = \\int_{W(x)} \\left| \\Delta I^{\\mathsf{T}}b + I_t\\right|^2 dx'\n",
    "\\rightarrow \\mathrm{min}\\ .\n",
    "$$\n",
    "\n",
    "然后对于$b$求导得到结果！\n",
    "\n",
    "- Affine motion:\n",
    "\n",
    "使用**Small Deformation**假设下的模型最小化平方和，如下所示：\n",
    "$$\n",
    "E(b) = \\int_{W(x)} \\left| \\Delta I(x')^{\\mathsf{T}} S(x')p + I_t(x') \\right|^2 dx'\n",
    "\\rightarrow \\mathrm{min}\\ .\n",
    "$$\n",
    "\n",
    "然后对于$p$求导得到结果！\n",
    "\n",
    "以上$b$与$p$均为向量表示！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When can Small Motion be Estimated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [孔径问题(aperture problem.)](https://blog.csdn.net/hankai1024/article/details/23433157)\n",
    "\n",
    "Lucas-Kanade会遇到孔径问题，如遇到白墙（if the region\n",
    "in the window W(x) around the point x has entirely constant\n",
    "intensity (for example a white wall)），在这种情况下：所有在窗内的点对应$ \\Delta I(x) = 0 $ 与 $ I_t(x) = 0 $或接近于。\n",
    "\n",
    "因此，structure tensor/matrix即：\n",
    "$$\n",
    "M(x) = \\int_{W(x)}\n",
    "\\left(\n",
    "\\begin{array}{cc}\n",
    "I_x^2  & I_xI_y \\\\\n",
    "I_xI_y & I_y^2\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$\n",
    "必须是可逆的。\n",
    "\n",
    "若$ \\mathrm{det}(M) $尽管不可逆但不等于，还是可以对法向运动进行估计。(estimate the normal motion, i.e. the motion in direction of the image gradient)\n",
    "\n",
    "进而到处以下的特征跟踪器（This leads to the following simple feature tracker）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Simple Feature Tracking Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对于每个时间片段，计算每个点的Structure tensor (For a given time instance t, compute at each point $ x \\in \\Omega $ the structure tensor)：\n",
    "$$\n",
    "M(x) = \\int_{W(x)}\n",
    "\\left(\n",
    "\\begin{array}{cc}\n",
    "I_x^2  & I_xI_y \\\\\n",
    "I_xI_y & I_y^2\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "- 选取对应矩阵行列式$ \\mathrm{det}(M) $超过阈值的点$ \\theta > 0$\n",
    "\n",
    "- 计算对应速度：\n",
    "$$\n",
    "b(x, t) = -M(x)^{-1} \\left(\n",
    "\\begin{array}{c}\n",
    "\\int I_x I_t dx' \\\\\n",
    "\\int I_y I_t dx'\n",
    "\\end{array}\n",
    "\\right)\\ .\n",
    "$$\n",
    "\n",
    "- 然后重复上述步骤。\n",
    "\n",
    "**局限**：如果邻域间的光度变化不是非常的大，那么可能造成$I_x$与$I_y$非常小，可能无法超过"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Point Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robust Feature Point Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**局限**：矩阵逆可能十分不稳定（the inverse of M(x) may not be very stable），从而导致在一些情况下，M的行列式非常小，因此有些情况$\\mathrm{det} (M) \\not= 0 $不一定适合跟踪。\n",
    "\n",
    "**解决方案**：开发出相关经典特征子如Moravec ’80, Förstner ’84, ’87 and Harris & Stephens ’88。\n",
    "\n",
    "其中一种方法：就是在$ M(x) $上加上与特征点中心相关的高斯分布（Gaussian distribution）实现基于高斯的权重分配：\n",
    "$$\n",
    "M(x) \n",
    "=G_{\\sigma} \\star \\Delta I \\Delta I^{\\mathsf{T}}\n",
    "=\\int_{W(x)}\n",
    "G_{\\sigma}(x-x')\n",
    "\\left(\n",
    "\\begin{array}{cc}\n",
    "I_x^2  & I_xI_y \\\\\n",
    "I_xI_y & I_y^2\n",
    "\\end{array}\n",
    "\\right)\n",
    "(x')dx'\n",
    "$$\n",
    "\n",
    "Harris提出了如下方法：\n",
    "$$\n",
    "C(x) = \\mathrm{det}(M) - \\kappa mathrm{trace}^{2}(M)\\ ,\n",
    "$$\n",
    "然后选取其中$ C(x) > \\theta $进行二次筛选，找到更为健壮robust的点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide Baseline Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "唯一非常大，难以直接匹配（displacement is very much\n",
    "many points cannot match\n",
    "substantial rotation）\n",
    "\n",
    "large parts of the image plane will not match at all because they are not visible in the other image. In other words, while a given point may have many potential matches, quite possibly it does not have a corresponding point in the other image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extensions to Larger Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跟踪一大局限：隔帧之间的差别在大部分情况下非常小，因此可能不断积累小错误One of the limitations of tracking features frame by frame is that small errors in the motion accumulate over time。\n",
    "\n",
    "其中一个方法就是与第一帧进行比对，找到相对更大的区别，或者选取关键帧。A remedy is to **match a given point back to the first frame**. This generally implies **larger displacements between frames.**\n",
    "\n",
    "并且有两个方面的想法去解决大偏移：\n",
    "\n",
    "- motion of the window between frames is **(in general) no longer translational**, for example by using an **affine motion model**.\n",
    "\n",
    "- replace the sum-of-squared-differences by the **normalized cross correlation** which is more **robust to illumination changes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized Cross Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要定义如下：\n",
    "$$\n",
    "\\mathrm{NCC}(h)\n",
    "= \\frac\n",
    "{\n",
    "\\int_{W(x)} \n",
    "\\left( I_1(x') - \\overline{I_1}\\right)\n",
    "\\left( I_2(h(x')) - \\overline{I_2}\\right) dx'\n",
    "}\n",
    "{\\sqrt{\\int_{W(x)} \n",
    "\\left( I_1(x') - \\overline{I_1}\\right)^2 dx'\n",
    "\\int_{W(x)}\\left( I_2(h(x')) - \\overline{I_2}\\right)^2 dx'}}\n",
    "$$\n",
    "\n",
    "- 通过减去平均值，可以对于额外的增量不变（By subtracting this average intensity, the measure becomes invariant to additive intensity changes） $ I \\rightarrow I + \\gamma $\n",
    "\n",
    "- 通过除以方差，可以对于成倍的光照变化不变（Dividing by the intensity variances of each window makes the\n",
    "measure invariant to multiplicative changes） $ I \\rightarrow \\gamma I  $\n",
    "\n",
    "❗ 对于本页后续部分，还没理解待补充"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special Case: Optimal Affine Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已知有仿射模型：\n",
    "$$\n",
    "h(x) = Ax + d,\n",
    "$$\n",
    "然后最大化正则互相关，对一直矩阵，如下所示：\n",
    "$$\n",
    "\\hat{A}, \\hat{d} = \\arg \\max_{A,d} NCC(A,d}\n",
    "$$\n",
    "\n",
    "然后将上述模型中的$ h(x') $替换成$Ax' + d$仿射模型，但是求解有一定难度（Efficiently finding appropriate optima, however, is a challenge.）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
